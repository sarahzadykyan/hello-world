{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW 4\n",
    "\n",
    "**1)** tokenize alice.txt, please apply the tokenization function you wrote for hw3 -- 1 point;\n",
    "\n",
    "**2)** apply the gutenberg_file_wc function (also from hw3) to alice.txt to get the word counts -- 1 point;\n",
    "\n",
    "**3)** try to search for (word) initial consonant clusters using regular expression(s) (Don't forget to import re at the beginning of your program) -- 3 points;\n",
    "\n",
    "**4)** print the counts for all the clusters that you have identified, you should end up with a dictionary like {'pr': 26, 'sp': 15,...} -- 2 points;\n",
    "\n",
    "**5)** print the total number of different clusters you've identified, e.g., 10 clusters or 40 clusters -- 1 point;\n",
    "\n",
    "**6)** print the list of all the clusters in the alphabetical order, ['bl', 'br',...] -- 1 point;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'st': 29, 'pr': 20, 'sp': 9, 'pgd': 1, 'tw': 4, 'sl': 6, 'pl': 16, 'tr': 15, 'cl': 6, 'fl': 13, 'str': 4, 'fr': 11, 'gr': 17, 'dr': 14, 'll': 7, 'gl': 5, 'sm': 6, 'br': 15, 'thr': 6, 'cr': 20, 'sc': 1, 'spl': 3, 'sk': 3, 'shr': 4, 'sw': 6, 'spr': 1, 'sn': 4, 'scr': 5, 'sq': 1, 'bl': 6}\n",
      "30\n",
      "['bl', 'br', 'cl', 'cr', 'dr', 'fl', 'fr', 'gl', 'gr', 'll', 'pgd', 'pl', 'pr', 'sc', 'scr', 'shr', 'sk', 'sl', 'sm', 'sn', 'sp', 'spl', 'spr', 'sq', 'st', 'str', 'sw', 'thr', 'tr', 'tw']\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from string import punctuation\n",
    "def tokenize(s):\n",
    "    words = s.lower().strip().split() \n",
    "    twords = [word.strip(punctuation) for word in words] \n",
    "    return twords\n",
    "#2\n",
    "def gutenberg_file_wc(s):\n",
    "    alice = open('alice.txt').read()\n",
    "    a = alice.find(\"*** START OF THIS PROJECT GUTENBERG EBOOK\") \n",
    "    z = alice.find(\"*** END OF THIS PROJECT GUTENBERG EBOOK\") \n",
    "    alice_new = alice[a:z]\n",
    "    #alice.close() - возник вопрос, нужно ли закрывать файл или не обязательно\n",
    "    alice_tokens=tokenize(alice_new)\n",
    "    d={}\n",
    "    for each_word in alice_tokens:\n",
    "        if each_word in d:\n",
    "            d[each_word] = d[each_word]+1\n",
    "        else:\n",
    "            d[each_word] = 1\n",
    "\n",
    "    return d\n",
    "#print(gutenberg_file_wc('alice.txt'))\n",
    "\n",
    "#3\n",
    "doc = {} \n",
    "doc = gutenberg_file_wc('alice.txt')\n",
    "wordss = list(doc.keys())\n",
    "wordst = ' '.join(wordss)\n",
    "import re\n",
    "wordsineed = re.findall('\\\\b([bcdfghjklmnpqrstvwxyz][bcdfghjklmnpqrstvwxz][bcdfghjklmnpqrstvwxz]?)', wordst)\n",
    "#print(wordsineed)\n",
    "\n",
    "#4\n",
    "clusters={}\n",
    "NB = ['sh','th','gh','wh','ch','kn','wr','www','htt']\n",
    "for each in wordsineed:\n",
    "    if each not in NB:\n",
    "        if each in clusters:\n",
    "            clusters[each] = clusters[each]+1\n",
    "        else:\n",
    "            clusters[each] = 1\n",
    "    else:  \n",
    "        continue\n",
    "        \n",
    "print (clusters)\n",
    "\n",
    "#5\n",
    "totalNumber = len(list(clusters.keys()))\n",
    "print(totalNumber)\n",
    "\n",
    "#6\n",
    "clustersKeys = list(clusters.keys())\n",
    "print (sorted(clustersKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
